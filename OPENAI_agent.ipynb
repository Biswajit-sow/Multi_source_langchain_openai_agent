{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3da0549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arxiv) (6.0.11)\n",
      "Requirement already satisfied: requests~=2.32.0 in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arxiv) (2.32.3)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests~=2.32.0->arxiv) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests~=2.32.0->arxiv) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e1e7c6",
   "metadata": {},
   "source": [
    "create a wrapper based on wikipidea and arxiv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "665d64a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wikipedia) (4.13.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wikipedia) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\biswajit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->wikipedia) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44568cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b87f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)#top_k_result define how many result you want and doc _content_chars_max define how many character you want to show in the summary\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d7d5665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae9d0b",
   "metadata": {},
   "source": [
    "using webbaseloader to load any data from any website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "103d4e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "C:\\Users\\Biswajit\\AppData\\Local\\Temp\\ipykernel_16904\\3099206296.py:10: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding = OllamaEmbeddings(model=\"tinyllama\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B07F590220>, search_kwargs={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")# the loader basically read the entire webpage and return it as a string\n",
    "docs=loader.load() #load the entire content from the particular website\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs) #chunk_overlap=determines how much overlap there should be between consecutive chunks\n",
    "\n",
    "embedding = OllamaEmbeddings(model=\"tinyllama\") \n",
    "vectordb=FAISS.from_documents(documents,embedding)\n",
    "#vectordb convert into retriever \n",
    "retriever=vectordb.as_retriever()\n",
    "\n",
    "retriever\n",
    "#retriever for wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcb32c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a retriever tool\n",
    "#Create a tool to do retrieval of documents.\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "#it is basically creating a tool to do the search for that particular page \n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith_search\",\n",
    "                      \"search  for information about Langsmith.For any question about Langsmith you must use this tools\")#retriever=retriever name,langsmith_search help to identify the tool name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9774751b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4829cd7e",
   "metadata": {},
   "source": [
    "3rd Retriever tool:ARXIV platform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e570980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "\n",
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=200)#top_k_result define how many result you want and doc _content_chars_max define how many character you want to show in the summary\n",
    "arxiv=ArxivQueryRun(api_wrapper=arxiv_wrapper)# create a arxiv wrrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61fa7aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c07697",
   "metadata": {},
   "source": [
    "Combining all the tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7ff094b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\Biswajit\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " Tool(name='langsmith_search', description='search  for information about Langsmith.For any question about Langsmith you must use this tools', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001B07F58E170>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B07F590220>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001B07F58E3B0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B07F590220>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools=[wiki,arxiv,retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc344df1",
   "metadata": {},
   "source": [
    "Step 2 :Query from the specific tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651fd31f",
   "metadata": {},
   "source": [
    "OPENAI agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ae590a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-3.5-turbo-0125\",temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aba4b3",
   "metadata": {},
   "source": [
    "There are two way to creating a prompt one is chat prompt  template and one is langchain hub- this is a generic prompt which is crate by many other user of langchain and also crate by langchain team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "191df7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "#get the prompt to use -you can modify this to suit your needs\n",
    "prompt= hub.pull(\"hwchase17/openai-functions-agent\")# 1st one is username that is prsent in the langchainhub  and other one is name of the function that you want to use\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03971400",
   "metadata": {},
   "source": [
    "OPEN_AI TOOL AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18aeef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "agent=create_openai_tools_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8effeff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001B078ABBE20>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001B078ABBE20>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001B07F593FD0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001B07F635720>, root_client=<openai.OpenAI object at 0x000001B07F593C10>, root_async_client=<openai.AsyncOpenAI object at 0x000001B07F635690>, model_name='gpt-3.5-turbo-0125', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'search  for information about Langsmith.For any question about Langsmith you must use this tools', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\Biswajit\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)), Tool(name='langsmith_search', description='search  for information about Langsmith.For any question about Langsmith you must use this tools', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001B07F58E170>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B07F590220>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001B07F58E3B0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001B07F590220>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to use this agent we have to use agent executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)#agentname ,tools name ,verbose help to get the details whenever I am getting a respone\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c17e4aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Naukri karla fir bharna payment\n"
     ]
    }
   ],
   "source": [
    "#in order to execute anything\n",
    "from openai import RateLimitError\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    # Attempt to execute agent\n",
    "    result = agent_executor.invoke({\"input\": \"Tell me about langsmith\"}) #so this agent will excute and interact from the tool that is related to langsmith (Webbaseloader)\n",
    "    print(result)\n",
    "\n",
    "except requests.exceptions.RequestException as e: # his is the first except block. It catches exceptions that occur during the HTTP request itself (e.g., network errors, connection errors, etc.).\n",
    "    print(f\"Error: {e}\") # Return the error message.\n",
    "\n",
    "except (KeyError, ValueError) as e: #:: This is the second except block. It catches KeyError(e.g., if the API response doesn't have the \"output\" or \"content\" keys) and ValueErro(e.g., if the API returns an invalid JSON string) exceptionss break down the get_openai_response and `get_ollama.\n",
    "    print(f\"Error parsing response: {e}\")\n",
    "\n",
    "except RateLimitError as e:\n",
    "    # Handle quota exceeded specifically\n",
    "    print(\"Naukri karla fir bharna payment\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Optional: handle other unexpected errors gracefully\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
